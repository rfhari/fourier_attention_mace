/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/e3nn/o3/_wigner.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))
from run_train args: Namespace(config=None, name='dimer-CP-lr-remove-adjusted-mace', seed=123, work_dir='.', log_dir='./logs', model_dir=None, checkpoints_dir=None, results_dir=None, downloads_dir=None, device='cuda', default_dtype='float64', distributed=False, log_level='INFO', error_table='PerAtomMAE', model='MACE', r_max=6.0, radial_type='bessel', num_radial_basis=8, num_cutoff_basis=5, pair_repulsion=False, distance_transform='None', interaction='RealAgnosticResidualInteractionBlock', interaction_first='RealAgnosticResidualInteractionBlock', max_ell=3, correlation=3, num_interactions=2, MLP_irreps='16x0e', radial_MLP='[64, 64, 64]', hidden_irreps=None, num_channels=256, max_L=2, gate='silu', scaling='rms_forces_scaling', avg_num_neighbors=1, compute_avg_num_neighbors=True, compute_stress=False, compute_forces=True, train_file='./custom_dataset/dimer_datasets/dimers_CP_train.xyz', valid_file='./custom_dataset/dimer_datasets/dimers_CP_test.xyz', valid_fraction=0.1, test_file='./custom_dataset/dimer_datasets/dimers_CP_test.xyz', test_dir=None, multi_processed_test=False, num_workers=0, pin_memory=True, atomic_numbers=None, mean=None, std=None, statistics_file=None, E0s='average', foundation_filter_elements=True, heads=None, multiheads_finetuning=True, weight_pt_head=1.0, num_samples_pt=1000, subselect_pt='random', pt_train_file=None, pt_valid_file=None, keep_isolated_atoms=False, energy_key='energy', forces_key='forces', virials_key='REF_virials', stress_key='REF_stress', dipole_key='REF_dipole', charges_key='REF_charges', loss='weighted', forces_weight=100.0, swa_forces_weight=10.0, energy_weight=10.0, swa_energy_weight=100.0, virials_weight=1.0, swa_virials_weight=10.0, stress_weight=1.0, swa_stress_weight=10.0, dipole_weight=1.0, swa_dipole_weight=1.0, config_type_weights='{"Default":1.0}', huber_delta=0.01, optimizer='adam', beta=0.9, batch_size=2, valid_batch_size=2, lr=0.01, swa_lr=0.001, weight_decay=5e-07, amsgrad=True, scheduler='ReduceLROnPlateau', lr_factor=0.8, scheduler_patience=5, lr_scheduler_gamma=0.9993, swa=True, start_swa=600, ema=True, ema_decay=0.99, max_num_epochs=800, patience=5, foundation_model=None, foundation_model_readout=True, eval_interval=3, keep_checkpoints=False, save_all_checkpoints=False, restart_latest=False, save_cpu=False, clip_grad=10.0, wandb=False, wandb_dir=None, wandb_project='', wandb_entity='', wandb_name='', wandb_log_hypers=['num_channels', 'max_L', 'correlation', 'lr', 'swa_lr', 'weight_decay', 'batch_size', 'max_num_epochs', 'start_swa', 'energy_weight', 'forces_weight'])
args model: MACE
2024-11-17 11:43:33.090 INFO: ===========VERIFYING SETTINGS===========
2024-11-17 11:43:33.090 INFO: MACE version: 0.3.7
2024-11-17 11:43:33.276 INFO: CUDA version: 11.8, CUDA device: 0
2024-11-17 11:43:33.399 INFO: ===========LOADING INPUT DATA===========
2024-11-17 11:43:33.399 INFO: Using heads: ['default']
2024-11-17 11:43:33.399 INFO: =============    Processing head default     ===========
2024-11-17 11:43:33.424 WARNING: Since ASE version 3.23.0b1, using energy_key 'energy' is no longer safe when communicating between MACE and ASE. We recommend using a different key, rewriting 'energy' to 'REF_energy'. You need to use --energy_key='REF_energy' to specify the chosen key name.
2024-11-17 11:43:33.426 WARNING: Since ASE version 3.23.0b1, using forces_key 'forces' is no longer safe when communicating between MACE and ASE. We recommend using a different key, rewriting 'forces' to 'REF_forces'. You need to use --forces_key='REF_forces' to specify the chosen key name.
2024-11-17 11:43:33.428 INFO: Training set [10 configs, 10 energy, 480 forces] loaded from './custom_dataset/dimer_datasets/dimers_CP_train.xyz'
2024-11-17 11:43:33.441 WARNING: Since ASE version 3.23.0b1, using energy_key 'energy' is no longer safe when communicating between MACE and ASE. We recommend using a different key, rewriting 'energy' to 'REF_energy'. You need to use --energy_key='REF_energy' to specify the chosen key name.
2024-11-17 11:43:33.441 WARNING: Since ASE version 3.23.0b1, using forces_key 'forces' is no longer safe when communicating between MACE and ASE. We recommend using a different key, rewriting 'forces' to 'REF_forces'. You need to use --forces_key='REF_forces' to specify the chosen key name.
2024-11-17 11:43:33.442 INFO: Validation set [3 configs, 3 energy, 144 forces] loaded from './custom_dataset/dimer_datasets/dimers_CP_test.xyz'
2024-11-17 11:43:33.446 WARNING: Since ASE version 3.23.0b1, using energy_key 'energy' is no longer safe when communicating between MACE and ASE. We recommend using a different key, rewriting 'energy' to 'REF_energy'. You need to use --energy_key='REF_energy' to specify the chosen key name.
2024-11-17 11:43:33.446 WARNING: Since ASE version 3.23.0b1, using forces_key 'forces' is no longer safe when communicating between MACE and ASE. We recommend using a different key, rewriting 'forces' to 'REF_forces'. You need to use --forces_key='REF_forces' to specify the chosen key name.
2024-11-17 11:43:33.447 INFO: Test set (3 configs) loaded from './custom_dataset/dimer_datasets/dimers_CP_test.xyz':
2024-11-17 11:43:33.447 INFO: Default_Default: 3 configs, 3 energy, 144 forces
2024-11-17 11:43:33.447 INFO: Total number of configurations: train=10, valid=3, tests=[Default_Default: 3],
2024-11-17 11:43:33.447 INFO: Atomic Numbers used: [1, 6, 8]
2024-11-17 11:43:33.447 INFO: Isolated Atomic Energies (E0s) not in training file, using command line argument
2024-11-17 11:43:33.447 INFO: Computing average Atomic Energies using least squares regression
2024-11-17 11:43:33.448 INFO: Atomic Energies used (z: eV) for head default: {1: -886.5855785238405, 6: -394.0380348994849, 8: -295.5285261746135}
2024-11-17 11:43:33.457 INFO: Computing average number of neighbors
2024-11-17 11:43:33.603 INFO: Average number of neighbors: 9.75
2024-11-17 11:43:33.603 INFO: During training the following quantities will be reported: energy, forces
2024-11-17 11:43:33.603 INFO: ===========MODEL DETAILS===========
2024-11-17 11:43:33.612 INFO: Building model
2024-11-17 11:43:33.612 INFO: Message passing with 256 channels and max_L=2 (256x0e+256x1o+256x2e)
2024-11-17 11:43:33.613 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3
2024-11-17 11:43:33.613 INFO: 8 radial and 5 basis functions
2024-11-17 11:43:33.613 INFO: Radial cutoff: 6.0 A (total receptive field for each atom: 12.0 A)
2024-11-17 11:43:33.613 INFO: Distance transform for radial basis functions: None
2024-11-17 11:43:33.613 INFO: Hidden irreps: 256x0e+256x1o+256x2e
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
/trace/group/mcgaughey/hariharr/miniconda3/envs/mace/lib/python3.9/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn(
in the linear readout block 256x0e 16x0e 1
2024-11-17 11:43:36.123 INFO: Total number of parameters: 3590672
2024-11-17 11:43:36.123 INFO: 
2024-11-17 11:43:36.123 INFO: ===========OPTIMIZER INFORMATION===========
2024-11-17 11:43:36.123 INFO: Using ADAM as parameter optimizer
2024-11-17 11:43:36.123 INFO: Batch size: 2
2024-11-17 11:43:36.123 INFO: Using Exponential Moving Average with decay: 0.99
2024-11-17 11:43:36.123 INFO: Number of gradient updates: 4000
2024-11-17 11:43:36.123 INFO: Learning rate: 0.01, weight decay: 5e-07
2024-11-17 11:43:36.123 INFO: WeightedEnergyForcesLoss(energy_weight=10.000, forces_weight=100.000)
2024-11-17 11:43:36.124 INFO: Stage Two (after 600 epochs) with loss function: WeightedEnergyForcesLoss(energy_weight=100.000, forces_weight=10.000), with energy weight : 100.0, forces weight : 10.0 and learning rate : 0.001
2024-11-17 11:43:36.246 INFO: Using gradient clipping with tolerance=10.000
2024-11-17 11:43:36.246 INFO: 
2024-11-17 11:43:36.246 INFO: ===========TRAINING===========
2024-11-17 11:43:36.246 INFO: Started training, reporting errors on validation set
2024-11-17 11:43:36.247 INFO: Loss metrics on validation set
2024-11-17 11:43:36.586 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:43:36.690 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:43:36.698 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:43:37.929 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:43:37.934 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:43:37.934 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:43:37.935 INFO: total_energy: torch.Size([2])
2024-11-17 11:43:37.935 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:43:37.935 INFO: node_energy: torch.Size([32])
2024-11-17 11:43:38.997 INFO: node_feats: torch.Size([16, 2304])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:43:39.109 INFO: node_feats: torch.Size([16, 256])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:43:39.118 INFO: node_feats_out:torch.Size([16, 256]), torch.Size([2560]), 16
qkv: torch.Size([16, 4, 192]) torch.Size([16, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([16, 256])
2024-11-17 11:43:39.650 INFO: long_range_embedding: torch.Size([16, 256])
2024-11-17 11:43:39.655 INFO: long_range_energy: torch.Size([16, 1]), torch.Size([1])
2024-11-17 11:43:39.655 INFO: contributions: torch.Size([1, 4]), 4, torch.Size([1])
2024-11-17 11:43:39.655 INFO: total_energy: torch.Size([1])
2024-11-17 11:43:39.655 INFO: node_energy_contributions: torch.Size([16, 4])
2024-11-17 11:43:39.656 INFO: node_energy: torch.Size([16])
2024-11-17 11:43:40.042 INFO: Initial: head: default, loss=  0.0990, MAE_E_per_atom=    27.1 meV, MAE_F=    27.1 meV / A
2024-11-17 11:43:41.549 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:43:41.633 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:43:41.639 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:43:42.917 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:43:42.923 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:43:42.923 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:43:42.924 INFO: total_energy: torch.Size([2])
2024-11-17 11:43:42.924 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:43:42.924 INFO: node_energy: torch.Size([32])
2024-11-17 11:43:49.863 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:43:49.941 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:43:49.946 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:43:51.064 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:43:51.066 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:43:51.067 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:43:51.067 INFO: total_energy: torch.Size([2])
2024-11-17 11:43:51.067 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:43:51.067 INFO: node_energy: torch.Size([32])
2024-11-17 11:43:57.307 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:43:57.379 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:43:57.383 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:43:58.417 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:43:58.419 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:43:58.419 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:43:58.420 INFO: total_energy: torch.Size([2])
2024-11-17 11:43:58.420 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:43:58.420 INFO: node_energy: torch.Size([32])
2024-11-17 11:44:06.552 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:06.625 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:06.629 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:44:07.659 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:44:07.661 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:44:07.661 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:44:07.661 INFO: total_energy: torch.Size([2])
2024-11-17 11:44:07.662 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:44:07.662 INFO: node_energy: torch.Size([32])
2024-11-17 11:44:17.920 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:17.992 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:17.997 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:44:18.987 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:44:18.989 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:44:18.989 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:44:18.990 INFO: total_energy: torch.Size([2])
2024-11-17 11:44:18.990 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:44:18.990 INFO: node_energy: torch.Size([32])
2024-11-17 11:44:29.015 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:29.087 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:29.091 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:44:30.696 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:44:30.700 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:44:30.700 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:44:30.701 INFO: total_energy: torch.Size([2])
2024-11-17 11:44:30.701 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:44:30.701 INFO: node_energy: torch.Size([32])
2024-11-17 11:44:31.468 INFO: node_feats: torch.Size([16, 2304])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:44:31.596 INFO: node_feats: torch.Size([16, 256])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:44:31.603 INFO: node_feats_out:torch.Size([16, 256]), torch.Size([2560]), 16
qkv: torch.Size([16, 4, 192]) torch.Size([16, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([16, 256])
2024-11-17 11:44:32.552 INFO: long_range_embedding: torch.Size([16, 256])
2024-11-17 11:44:32.555 INFO: long_range_energy: torch.Size([16, 1]), torch.Size([1])
2024-11-17 11:44:32.555 INFO: contributions: torch.Size([1, 4]), 4, torch.Size([1])
2024-11-17 11:44:32.556 INFO: total_energy: torch.Size([1])
2024-11-17 11:44:32.556 INFO: node_energy_contributions: torch.Size([16, 4])
2024-11-17 11:44:32.556 INFO: node_energy: torch.Size([16])
2024-11-17 11:44:33.009 INFO: Epoch 0: head: default, loss=  0.1204, MAE_E_per_atom=     3.0 meV, MAE_F=    34.8 meV / A
2024-11-17 11:44:33.714 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:33.867 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:33.875 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:44:35.906 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:44:35.909 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:44:35.910 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:44:35.910 INFO: total_energy: torch.Size([2])
2024-11-17 11:44:35.911 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:44:35.911 INFO: node_energy: torch.Size([32])
2024-11-17 11:44:39.562 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:39.714 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:39.723 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:44:41.622 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:44:41.625 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:44:41.626 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:44:41.626 INFO: total_energy: torch.Size([2])
2024-11-17 11:44:41.627 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:44:41.627 INFO: node_energy: torch.Size([32])
2024-11-17 11:44:45.235 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:45.381 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:45.390 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:44:47.503 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:44:47.509 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:44:47.510 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:44:47.510 INFO: total_energy: torch.Size([2])
2024-11-17 11:44:47.511 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:44:47.511 INFO: node_energy: torch.Size([32])
2024-11-17 11:44:51.332 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:51.484 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:51.493 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:44:52.988 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:44:52.990 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:44:52.990 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:44:52.990 INFO: total_energy: torch.Size([2])
2024-11-17 11:44:52.991 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:44:52.991 INFO: node_energy: torch.Size([32])
2024-11-17 11:44:55.913 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:55.981 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:55.985 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:44:56.980 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:44:56.982 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:44:56.982 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:44:56.982 INFO: total_energy: torch.Size([2])
2024-11-17 11:44:56.983 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:44:56.983 INFO: node_energy: torch.Size([32])
2024-11-17 11:44:59.865 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:59.936 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:44:59.940 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:00.945 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:00.948 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:00.948 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:00.948 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:00.948 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:00.949 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:03.839 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:04.094 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:04.102 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:06.096 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:06.100 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:06.101 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:06.101 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:06.102 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:06.102 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:09.899 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:10.055 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:10.064 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:12.068 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:12.072 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:12.072 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:12.073 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:12.073 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:12.073 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:16.057 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:16.216 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:16.224 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:18.332 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:18.337 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:18.337 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:18.338 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:18.338 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:18.339 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:22.332 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:22.490 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:22.499 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:24.650 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:24.654 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:24.654 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:24.655 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:24.655 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:24.655 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:28.491 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:28.631 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:28.639 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:30.557 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:30.561 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:30.562 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:30.562 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:30.562 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:30.563 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:34.192 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:34.337 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:34.345 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:36.309 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:36.313 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:36.313 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:36.314 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:36.314 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:36.315 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:40.096 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:40.242 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:40.252 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:42.258 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:42.261 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:42.262 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:42.262 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:42.263 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:42.263 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:46.156 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:46.315 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:46.324 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:48.472 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:48.476 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:48.476 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:48.477 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:48.477 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:48.477 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:52.486 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:52.635 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:52.643 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:45:54.725 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:45:54.730 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:45:54.730 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:45:54.731 INFO: total_energy: torch.Size([2])
2024-11-17 11:45:54.731 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:45:54.731 INFO: node_energy: torch.Size([32])
2024-11-17 11:45:58.555 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:58.681 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:45:58.687 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:00.514 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:00.517 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:00.518 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:00.518 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:00.518 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:00.519 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:04.883 INFO: node_feats: torch.Size([16, 2304])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:46:04.950 INFO: node_feats: torch.Size([16, 256])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:46:04.953 INFO: node_feats_out:torch.Size([16, 256]), torch.Size([2560]), 16
qkv: torch.Size([16, 4, 192]) torch.Size([16, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([16, 256])
2024-11-17 11:46:05.486 INFO: long_range_embedding: torch.Size([16, 256])
2024-11-17 11:46:05.488 INFO: long_range_energy: torch.Size([16, 1]), torch.Size([1])
2024-11-17 11:46:05.488 INFO: contributions: torch.Size([1, 4]), 4, torch.Size([1])
2024-11-17 11:46:05.488 INFO: total_energy: torch.Size([1])
2024-11-17 11:46:05.488 INFO: node_energy_contributions: torch.Size([16, 4])
2024-11-17 11:46:05.489 INFO: node_energy: torch.Size([16])
2024-11-17 11:46:05.856 INFO: Epoch 3: head: default, loss=  0.0412, MAE_E_per_atom=     1.3 meV, MAE_F=    17.5 meV / A
2024-11-17 11:46:06.375 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:06.450 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:06.454 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:07.504 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:07.506 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:07.507 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:07.507 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:07.507 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:07.507 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:10.518 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:10.591 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:10.595 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:11.657 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:11.659 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:11.659 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:11.660 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:11.660 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:11.660 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:14.506 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:14.579 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:14.583 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:15.721 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:15.723 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:15.723 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:15.724 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:15.724 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:15.724 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:18.695 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:18.771 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:18.776 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:19.862 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:19.864 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:19.865 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:19.865 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:19.865 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:19.865 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:23.045 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:23.121 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:23.126 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:24.189 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:24.191 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:24.191 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:24.191 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:24.192 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:24.192 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:27.128 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:27.200 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:27.204 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:28.204 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:28.206 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:28.206 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:28.207 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:28.207 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:28.207 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:31.145 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:31.224 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:31.229 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:32.412 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:32.415 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:32.415 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:32.415 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:32.415 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:32.416 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:35.422 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:35.492 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:35.496 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:36.537 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:36.539 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:36.540 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:36.540 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:36.540 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:36.540 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:39.545 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:39.615 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:39.620 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:40.636 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:40.639 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:40.639 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:40.639 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:40.639 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:40.640 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:43.499 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:43.574 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:43.579 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:44.619 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:44.621 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:44.621 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:44.622 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:44.622 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:44.622 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:47.785 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:47.866 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:47.871 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:48.978 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:48.980 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:48.980 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:48.981 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:48.981 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:48.981 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:51.917 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:51.990 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:51.994 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:53.064 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:53.067 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:53.067 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:53.067 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:53.067 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:53.068 INFO: node_energy: torch.Size([32])
2024-11-17 11:46:56.116 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:56.190 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:46:56.194 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:46:57.210 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:46:57.212 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:46:57.212 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:46:57.212 INFO: total_energy: torch.Size([2])
2024-11-17 11:46:57.213 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:46:57.213 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:00.197 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:00.278 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:00.283 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:01.407 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:01.410 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:01.410 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:01.410 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:01.411 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:01.411 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:04.416 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:04.493 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:04.498 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:05.713 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:05.715 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:05.716 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:05.716 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:05.716 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:05.716 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:09.156 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:09.272 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:09.278 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:11.253 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:11.257 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:11.258 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:11.258 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:11.259 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:11.259 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:12.145 INFO: node_feats: torch.Size([16, 2304])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:47:12.213 INFO: node_feats: torch.Size([16, 256])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:47:12.217 INFO: node_feats_out:torch.Size([16, 256]), torch.Size([2560]), 16
qkv: torch.Size([16, 4, 192]) torch.Size([16, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([16, 256])
2024-11-17 11:47:12.763 INFO: long_range_embedding: torch.Size([16, 256])
2024-11-17 11:47:12.765 INFO: long_range_energy: torch.Size([16, 1]), torch.Size([1])
2024-11-17 11:47:12.765 INFO: contributions: torch.Size([1, 4]), 4, torch.Size([1])
2024-11-17 11:47:12.766 INFO: total_energy: torch.Size([1])
2024-11-17 11:47:12.766 INFO: node_energy_contributions: torch.Size([16, 4])
2024-11-17 11:47:12.766 INFO: node_energy: torch.Size([16])
2024-11-17 11:47:13.147 INFO: Epoch 6: head: default, loss=  0.0755, MAE_E_per_atom=     5.0 meV, MAE_F=    21.0 meV / A
2024-11-17 11:47:13.241 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:13.319 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:13.323 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:14.548 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:14.551 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:14.551 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:14.551 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:14.552 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:14.552 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:17.634 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:17.711 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:17.715 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:18.849 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:18.852 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:18.852 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:18.853 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:18.853 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:18.853 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:21.961 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:22.037 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:22.041 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:23.113 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:23.115 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:23.115 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:23.115 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:23.116 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:23.116 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:26.104 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:26.182 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:26.187 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:27.281 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:27.283 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:27.283 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:27.284 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:27.284 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:27.284 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:30.359 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:30.437 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:30.441 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:31.658 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:31.661 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:31.661 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:31.661 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:31.661 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:31.662 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:34.685 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:34.761 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:34.766 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:35.854 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:35.857 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:35.857 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:35.857 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:35.857 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:35.858 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:38.898 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:38.972 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:38.977 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:40.089 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:40.091 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:40.091 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:40.092 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:40.092 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:40.092 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:43.121 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:43.199 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:43.204 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:44.303 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:44.305 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:44.305 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:44.306 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:44.306 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:44.306 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:47.447 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:47.521 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:47.526 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:48.574 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:48.576 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:48.576 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:48.577 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:48.577 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:48.577 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:51.745 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:51.904 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:51.914 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:53.382 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:53.384 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:53.384 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:53.385 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:53.385 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:53.385 INFO: node_energy: torch.Size([32])
2024-11-17 11:47:56.501 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:56.579 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:47:56.584 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:47:57.686 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:47:57.688 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:47:57.689 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:47:57.689 INFO: total_energy: torch.Size([2])
2024-11-17 11:47:57.689 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:47:57.689 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:00.675 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:00.751 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:00.755 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:01.853 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:01.856 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:01.856 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:01.856 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:01.856 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:01.857 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:04.913 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:04.984 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:04.988 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:06.019 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:06.021 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:06.021 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:06.022 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:06.022 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:06.022 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:09.029 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:09.107 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:09.111 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:10.198 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:10.200 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:10.201 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:10.201 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:10.201 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:10.201 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:13.355 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:13.433 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:13.438 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:14.562 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:14.564 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:14.565 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:14.565 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:14.565 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:14.565 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:17.658 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:17.727 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:17.731 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:18.778 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:18.780 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:18.780 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:18.781 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:18.781 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:18.781 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:19.528 INFO: node_feats: torch.Size([16, 2304])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:48:19.600 INFO: node_feats: torch.Size([16, 256])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:48:19.603 INFO: node_feats_out:torch.Size([16, 256]), torch.Size([2560]), 16
qkv: torch.Size([16, 4, 192]) torch.Size([16, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([16, 256])
2024-11-17 11:48:20.153 INFO: long_range_embedding: torch.Size([16, 256])
2024-11-17 11:48:20.155 INFO: long_range_energy: torch.Size([16, 1]), torch.Size([1])
2024-11-17 11:48:20.155 INFO: contributions: torch.Size([1, 4]), 4, torch.Size([1])
2024-11-17 11:48:20.156 INFO: total_energy: torch.Size([1])
2024-11-17 11:48:20.156 INFO: node_energy_contributions: torch.Size([16, 4])
2024-11-17 11:48:20.156 INFO: node_energy: torch.Size([16])
2024-11-17 11:48:20.544 INFO: Epoch 9: head: default, loss=  0.1765, MAE_E_per_atom=     9.8 meV, MAE_F=    27.5 meV / A
2024-11-17 11:48:20.640 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:20.720 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:20.724 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:21.947 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:21.950 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:21.950 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:21.950 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:21.951 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:21.951 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:24.980 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:25.059 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:25.063 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:26.206 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:26.208 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:26.208 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:26.209 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:26.209 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:26.209 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:29.374 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:29.450 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:29.455 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:30.516 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:30.518 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:30.518 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:30.519 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:30.519 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:30.519 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:33.481 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:33.558 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:33.562 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:34.640 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:34.643 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:34.643 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:34.643 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:34.643 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:34.644 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:37.835 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:37.911 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:37.915 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:38.999 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:39.002 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:39.002 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:39.002 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:39.003 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:39.003 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:42.016 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:42.092 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:42.097 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:43.139 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:43.142 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:43.142 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:43.142 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:43.143 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:43.143 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:46.094 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:46.169 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:46.173 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:47.261 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:47.263 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:47.263 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:47.264 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:47.264 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:47.264 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:50.350 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:50.425 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:50.431 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:51.509 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:51.511 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:51.511 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:51.512 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:51.512 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:51.512 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:54.623 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:54.701 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:54.706 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:55.742 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:55.744 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:55.744 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:55.745 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:55.745 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:55.745 INFO: node_energy: torch.Size([32])
2024-11-17 11:48:58.615 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:58.684 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:48:58.688 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:48:59.714 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:48:59.716 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:48:59.717 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:48:59.717 INFO: total_energy: torch.Size([2])
2024-11-17 11:48:59.717 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:48:59.717 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:02.798 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:02.872 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:02.876 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:03.883 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:03.885 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:03.885 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:03.886 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:03.886 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:03.886 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:06.865 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:06.934 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:06.938 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:08.029 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:08.031 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:08.031 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:08.032 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:08.032 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:08.032 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:11.198 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:11.272 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:11.277 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:12.359 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:12.361 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:12.362 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:12.362 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:12.362 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:12.362 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:15.401 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:15.478 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:15.483 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:16.602 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:16.605 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:16.605 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:16.605 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:16.605 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:16.606 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:19.832 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:19.908 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:19.913 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:21.022 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:21.024 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:21.025 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:21.025 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:21.025 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:21.025 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:24.117 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:24.187 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:24.190 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:25.269 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:25.271 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:25.271 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:25.271 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:25.271 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:25.272 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:25.969 INFO: node_feats: torch.Size([16, 2304])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:49:26.033 INFO: node_feats: torch.Size([16, 256])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:49:26.037 INFO: node_feats_out:torch.Size([16, 256]), torch.Size([2560]), 16
qkv: torch.Size([16, 4, 192]) torch.Size([16, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([16, 256])
2024-11-17 11:49:26.540 INFO: long_range_embedding: torch.Size([16, 256])
2024-11-17 11:49:26.542 INFO: long_range_energy: torch.Size([16, 1]), torch.Size([1])
2024-11-17 11:49:26.542 INFO: contributions: torch.Size([1, 4]), 4, torch.Size([1])
2024-11-17 11:49:26.542 INFO: total_energy: torch.Size([1])
2024-11-17 11:49:26.542 INFO: node_energy_contributions: torch.Size([16, 4])
2024-11-17 11:49:26.542 INFO: node_energy: torch.Size([16])
2024-11-17 11:49:26.906 INFO: Epoch 12: head: default, loss=  0.2773, MAE_E_per_atom=    14.0 meV, MAE_F=    33.6 meV / A
2024-11-17 11:49:26.998 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:27.072 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:27.077 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:28.242 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:28.244 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:28.244 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:28.244 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:28.244 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:28.245 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:31.146 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:31.218 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:31.222 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:32.233 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:32.235 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:32.235 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:32.235 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:32.236 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:32.236 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:35.320 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:35.394 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:35.398 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:36.428 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:36.430 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:36.431 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:36.431 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:36.431 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:36.431 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:39.335 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:39.406 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:39.410 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:40.430 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:40.432 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:40.432 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:40.433 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:40.433 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:40.433 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:43.411 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:43.474 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:43.478 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:44.471 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:44.473 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:44.474 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:44.474 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:44.474 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:44.474 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:47.490 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:47.564 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:47.568 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:48.614 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:48.616 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:48.617 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:48.617 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:48.617 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:48.617 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:51.518 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:51.586 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:51.591 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:52.574 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:52.577 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:52.577 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:52.577 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:52.577 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:52.577 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:55.341 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:55.409 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:55.413 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:49:56.375 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:49:56.377 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:49:56.378 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:49:56.378 INFO: total_energy: torch.Size([2])
2024-11-17 11:49:56.378 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:49:56.378 INFO: node_energy: torch.Size([32])
2024-11-17 11:49:59.346 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:59.454 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:49:59.460 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:01.108 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:01.112 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:01.112 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:01.112 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:01.113 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:01.113 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:04.404 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:04.475 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:04.480 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:05.490 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:05.492 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:05.492 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:05.493 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:05.493 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:05.493 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:08.501 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:08.570 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:08.575 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:09.647 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:09.649 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:09.650 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:09.650 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:09.650 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:09.650 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:12.553 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:12.628 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:12.633 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:13.723 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:13.726 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:13.726 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:13.726 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:13.727 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:13.727 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:17.320 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:17.480 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:17.489 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:19.634 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:19.638 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:19.638 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:19.639 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:19.639 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:19.639 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:23.406 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:23.555 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:23.563 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:25.740 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:25.745 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:25.745 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:25.746 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:25.746 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:25.746 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:29.418 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:29.494 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:29.498 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:30.578 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:30.580 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:30.580 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:30.581 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:30.581 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:30.581 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:33.555 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:33.619 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:33.622 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:34.653 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:34.654 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:34.655 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:34.655 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:34.655 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:34.655 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:35.365 INFO: node_feats: torch.Size([16, 2304])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:50:35.430 INFO: node_feats: torch.Size([16, 256])
energy graph: torch.Size([1]) torch.Size([16])
2024-11-17 11:50:35.433 INFO: node_feats_out:torch.Size([16, 256]), torch.Size([2560]), 16
qkv: torch.Size([16, 4, 192]) torch.Size([16, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([16, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([16, 256])
2024-11-17 11:50:35.948 INFO: long_range_embedding: torch.Size([16, 256])
2024-11-17 11:50:35.950 INFO: long_range_energy: torch.Size([16, 1]), torch.Size([1])
2024-11-17 11:50:35.950 INFO: contributions: torch.Size([1, 4]), 4, torch.Size([1])
2024-11-17 11:50:35.950 INFO: total_energy: torch.Size([1])
2024-11-17 11:50:35.950 INFO: node_energy_contributions: torch.Size([16, 4])
2024-11-17 11:50:35.951 INFO: node_energy: torch.Size([16])
2024-11-17 11:50:36.320 INFO: Epoch 15: head: default, loss=  0.2220, MAE_E_per_atom=    15.3 meV, MAE_F=    29.3 meV / A
2024-11-17 11:50:36.511 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:36.584 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:36.588 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:37.610 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:37.612 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:37.612 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:37.613 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:37.613 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:37.613 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:40.560 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:40.637 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:40.642 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:41.751 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:41.754 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:41.754 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:41.754 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:41.754 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:41.755 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:44.936 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:45.010 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:45.014 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:46.054 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:46.056 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:46.056 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:46.056 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:46.057 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:46.057 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:49.637 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:49.786 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:49.795 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:51.940 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:51.944 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:51.945 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:51.945 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:51.946 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:51.946 INFO: node_energy: torch.Size([32])
2024-11-17 11:50:55.814 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:55.891 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:50:55.896 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:50:56.977 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:50:56.979 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:50:56.979 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:50:56.980 INFO: total_energy: torch.Size([2])
2024-11-17 11:50:56.980 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:50:56.980 INFO: node_energy: torch.Size([32])
2024-11-17 11:51:00.034 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:51:00.110 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:51:00.115 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:51:01.179 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:51:01.181 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:51:01.181 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:51:01.182 INFO: total_energy: torch.Size([2])
2024-11-17 11:51:01.182 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:51:01.182 INFO: node_energy: torch.Size([32])
2024-11-17 11:51:04.195 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:51:04.269 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:51:04.273 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:51:05.343 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:51:05.345 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:51:05.345 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:51:05.345 INFO: total_energy: torch.Size([2])
2024-11-17 11:51:05.346 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:51:05.346 INFO: node_energy: torch.Size([32])
2024-11-17 11:51:08.246 INFO: node_feats: torch.Size([32, 2304])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:51:08.319 INFO: node_feats: torch.Size([32, 256])
energy graph: torch.Size([2]) torch.Size([32])
2024-11-17 11:51:08.323 INFO: node_feats_out:torch.Size([32, 256]), torch.Size([2560]), 32
qkv: torch.Size([32, 4, 192]) torch.Size([32, 3])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
vectors after split: torch.Size([4, 16, 64]) torch.Size([4, 16, 64]) torch.Size([4, 16, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
vectors after split: torch.Size([16, 64]) torch.Size([16, 64]) torch.Size([16, 64])
qkv after permute: torch.Size([32, 4, 192])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from value or key: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
k_vectors shape: torch.Size([983, 3]) torch.return_types.max(
values=tensor([ 7, 14, 14], device='cuda:0'),
indices=tensor([962, 171,  65], device='cuda:0')) torch.return_types.min(
values=tensor([0, 0, 0], device='cuda:0'),
indices=tensor([ 0,  0, 51], device='cuda:0'))
k_vectors dtype: torch.int64
value from optimized ewald sum: torch.Size([16, 64, 8, 15, 15])
term from query: torch.Size([16, 64, 983]) torch.Size([16, 64, 8, 15, 15]) torch.Size([983, 64])
q_pot: torch.Size([16, 64, 983]) torch.Size([983, 64]) torch.Size([983, 64])
weighted_values before ift: torch.Size([16, 983, 256]) torch.Size([16, 983, 64])
optimized_inverse: torch.Size([16, 3]) torch.Size([16, 3])
mesh grid shape: torch.Size([8, 15, 15]) torch.Size([8, 15, 15]) torch.Size([8, 15, 15])
valid_k: torch.Size([8, 15, 15])
shapes of q: torch.Size([16, 983, 256]) True
new_sum_term: torch.Size([16, 256]) 16
weighted_values after ift: torch.Size([16, 256])
results: torch.Size([32, 256])
2024-11-17 11:51:09.494 INFO: long_range_embedding: torch.Size([32, 256])
2024-11-17 11:51:09.496 INFO: long_range_energy: torch.Size([32, 1]), torch.Size([2])
2024-11-17 11:51:09.496 INFO: contributions: torch.Size([2, 4]), 4, torch.Size([2])
2024-11-17 11:51:09.497 INFO: total_energy: torch.Size([2])
2024-11-17 11:51:09.497 INFO: node_energy_contributions: torch.Size([32, 4])
2024-11-17 11:51:09.497 INFO: node_energy: torch.Size([32])
