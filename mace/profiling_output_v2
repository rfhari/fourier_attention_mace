Timer unit: 1e-06 s

Total time: 198.823 s
File: /trace/group/mcgaughey/hariharr/mace_exploration/fourier_attention_mace/mace/mace/modules/ewald_mace.py
Function: compute_potential_optimized at line 87

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    87                                               @profile
    88                                               def compute_potential_optimized(self, r_raw, q, box, vector_type):
    89      1980       9598.8      4.8      0.0          dtype = torch.complex64 if r_raw.dtype == torch.float32 else torch.complex128
    90      1980       3907.3      2.0      0.0          device = r_raw.device
    91                                           
    92      1980      43633.2     22.0      0.0          r = r_raw / box
    93                                           
    94      1980      72618.8     36.7      0.0          nk = (box / self.dl).int().tolist()
    95      1980      14309.2      7.2      0.0          nk = [max(1, k) for k in nk]
    96                                           
    97      1980       3984.2      2.0      0.0          n = r.shape[0]
    98      1980      40214.6     20.3      0.0          eikx = torch.ones((n, nk[0] + 1), dtype=dtype, device=device)
    99      1980      23232.8     11.7      0.0          eiky = torch.ones((n, 2 * nk[1] + 1), dtype=dtype, device=device)
   100      1980      15471.8      7.8      0.0          eikz = torch.ones((n, 2 * nk[2] + 1), dtype=dtype, device=device)
   101                                           
   102      1980     179117.7     90.5      0.1          eikx[:, 1] = torch.exp(1j * self.twopi * r[:, 0])
   103      1980      77508.9     39.1      0.0          eiky[:, nk[1] + 1] = torch.exp(1j * self.twopi * r[:, 1])
   104      1980      76207.4     38.5      0.0          eikz[:, nk[2] + 1] = torch.exp(1j * self.twopi * r[:, 2])
   105                                           
   106     13860       9823.2      0.7      0.0          for k in range(2, nk[0] + 1):
   107     11880     512289.9     43.1      0.3              eikx[:, k] = eikx[:, k - 1].clone() * eikx[:, 1].clone()
   108     13860       6933.6      0.5      0.0          for k in range(2, nk[1] + 1):
   109     11880     466240.0     39.2      0.2              eiky[:, nk[1] + k] = eiky[:, nk[1] + k - 1].clone() * eiky[:, nk[1] + 1].clone()
   110     13860       6379.5      0.5      0.0          for k in range(2, nk[2] + 1):
   111     11880     484513.7     40.8      0.2              eikz[:, nk[2] + k] = eikz[:, nk[2] + k - 1].clone() * eikz[:, nk[2] + 1].clone()
   112                                           
   113     15840       6890.2      0.4      0.0          for k in range(nk[1]):
   114     13860     311531.1     22.5      0.2              eiky[:, k] = torch.conj(eiky[:, 2 * nk[1] - k])
   115     15840       6703.9      0.4      0.0          for k in range(nk[2]):
   116     13860     273482.7     19.7      0.1              eikz[:, k] = torch.conj(eikz[:, 2 * nk[2] - k])
   117                                           
   118      1980      36527.1     18.4      0.0          kx = torch.arange(nk[0] + 1, device=device)
   119      1980      12257.9      6.2      0.0          ky = torch.arange(-nk[1], nk[1] + 1, device=device)
   120      1980       6772.5      3.4      0.0          kz = torch.arange(-nk[2], nk[2] + 1, device=device)
   121                                           
   122      1980      72934.0     36.8      0.0          kx_term = (kx / box[0]) ** 2
   123      1980      25783.4     13.0      0.0          ky_term = (ky / box[1]) ** 2
   124      1980      26775.2     13.5      0.0          kz_term = (kz / box[2]) ** 2
   125                                           
   126      1980      13908.0      7.0      0.0          kx_sq = kx_term.view(-1, 1, 1)
   127      1980       3997.9      2.0      0.0          ky_sq = ky_term.view(1, -1, 1)
   128      1980       4361.3      2.2      0.0          kz_sq = kz_term.view(1, 1, -1)
   129                                           
   130      1980      71087.4     35.9      0.0          k_sq = self.twopi_sq * (kx_sq + ky_sq + kz_sq)
   131      1980      79391.7     40.1      0.0          mask = (k_sq <= self.k_sq_max) & (k_sq > 0)
   132                                           
   133      1980    5222662.9   2637.7      2.6          kfac = torch.exp(-self.sigma_sq_half * k_sq) / k_sq
   134      1980      89449.4     45.2      0.0          kfac[~mask] = 0
   135                                           
   136      1980      45404.0     22.9      0.0          eikx_expanded = eikx.unsqueeze(2).unsqueeze(3)
   137      1980      18320.7      9.3      0.0          eiky_expanded = eiky.unsqueeze(1).unsqueeze(3)
   138      1980      16483.2      8.3      0.0          eikz_expanded = eikz.unsqueeze(1).unsqueeze(2)
   139                                           
   140      1980      32611.0     16.5      0.0          factor = torch.ones_like(kx, dtype=dtype, device=device)
   141      1980      46009.1     23.2      0.0          factor[1:] = 2.0
   142                                           
   143      1980       3454.2      1.7      0.0          if q.dim() == 1:
   144                                                       q_expanded = q.unsqueeze(1).unsqueeze(2).unsqueeze(3).unsqueeze(4)
   145      1980       1101.8      0.6      0.0          elif q.dim() == 2:
   146      1980      32175.0     16.3      0.0              q_expanded = q.unsqueeze(2).unsqueeze(3).unsqueeze(4)
   147                                                   else:
   148                                                       raise ValueError("q must be 1D or 2D tensor")
   149                                                   
   150      1980      57171.6     28.9      0.0          k_vectors = mask.nonzero()
   151      1980    1020962.3    515.6      0.5          print("box size:", box)
   152      1980      20985.0     10.6      0.0          print("k_vectors shape and dtype:", k_vectors.shape, k_vectors.dtype)
   153                                           
   154      1980   87538904.9  44211.6     44.0          value = q_expanded * (eikx_expanded * eiky_expanded * eikz_expanded).unsqueeze(1)
   155      1980      97282.0     49.1      0.0          print("value from optimized ewald sum:", value.shape)
   156      1980     152213.1     76.9      0.1          k_vectors_adjusted = k_vectors - 1
   157                                                   
   158                                                   # term = torch.stack([value[:, :, kx-1, ky-1, kz-1].sum(dim=0) for kx, ky, kz in k_vectors])
   159                                                   # term = term.transpose(0, 1)
   160                                           
   161      1980   45264572.2  22860.9     22.8          term_before_sum = value[:, :, k_vectors_adjusted[:, 0], k_vectors_adjusted[:, 1], k_vectors_adjusted[:, 2]]
   162                                                   # term_before_sum = value[:, :, k_vectors[:, 0], k_vectors[:, 1], k_vectors[:, 2]]
   163                                                   
   164      1980   55864576.4  28214.4     28.1          term = term_before_sum.sum(dim=0)
   165      1980     174234.9     88.0      0.1          term = term.transpose(0, 1)
   166                                           
   167      1980       3477.8      1.8      0.0          if vector_type == 'v' or vector_type == 'k':
   168      1320      78653.0     59.6      0.0              print("term from value or key:", term_before_sum.shape, value.shape, term.shape)
   169      1320        989.9      0.7      0.0              return_val = term
   170                                                   else:
   171       660      40993.8     62.1      0.0              print("term from query:", term_before_sum.shape, value.shape, term.shape)
   172       660        303.2      0.5      0.0              return_val = term_before_sum
   173                                           
   174                                                   # pot = (kfac.unsqueeze(0) * factor.view(1, -1, 1, 1) * torch.real(torch.conj(term) * term)).sum(dim=[1, 2, 3])
   175                                           
   176                                                   # pot /= (box[0] * box[1] * box[2])
   177                                           
   178                                                   # if self.remove_self_interaction:
   179                                                   #     pot -= torch.sum(q ** 2) / (self.sigma * self.twopi**(3./2.))
   180                                           
   181      1980       1464.6      0.7      0.0          return return_val #pot.real * self.norm_factor

198.82 seconds - /trace/group/mcgaughey/hariharr/mace_exploration/fourier_attention_mace/mace/mace/modules/ewald_mace.py:87 - compute_potential_optimized
